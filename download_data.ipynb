{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Stanford Large Movie Review Dataset\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  20.3M      0  0:00:03  0:00:03 --:--:-- 20.3M\n"
     ]
    }
   ],
   "source": [
    "!curl -o ./data/aclImdb.tar.gz https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xzf ./data/aclImdb.tar.gz -C ./data/\n",
    "!rm -rf ./data/aclImdb.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(742)\n",
    "# Textflint uses labels x (text) and y (sentiment) for Sentiment Analysis task\n",
    "pos = random.sample(glob.glob('./data/aclImdb/test/pos/*.txt'), 50)\n",
    "neg = random.sample(glob.glob('./data/aclImdb/test/neg/*.txt'), 50)\n",
    "\n",
    "pos_objects = []\n",
    "for filename in pos:\n",
    "    with open(filename, 'r') as file:\n",
    "        pos_objects.append({\n",
    "            'x': file.read(),\n",
    "            'y': 'pos'\n",
    "        })\n",
    "\n",
    "neg_objects = []\n",
    "for filename in neg:\n",
    "    with open(filename, 'r') as file:\n",
    "        neg_objects.append({\n",
    "            'x': file.read(),\n",
    "            'y': 'neg'\n",
    "        })\n",
    "\n",
    "with open('./data/aclImdb.json', 'w') as outfile:\n",
    "    for object in [*pos_objects, *neg_objects]:\n",
    "        outfile.write(json.dumps(object))\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Stanford Natural Language Inference Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 90.1M  100 90.0M    0     0  20.6M      0  0:00:04  0:00:03  0:00:01 20.6M.1M    0     0  22.5M      0  0:00:03  0:00:03 --:--:-- 22.5M\n",
      "Archive:  ./data/SNLI1.0.zip\n",
      "   creating: ./data/snli_1.0/\n",
      "  inflating: ./data/snli_1.0/.DS_Store  \n",
      "   creating: ./data/__MACOSX/\n",
      "   creating: ./data/__MACOSX/snli_1.0/\n",
      "  inflating: ./data/__MACOSX/snli_1.0/._.DS_Store  \n",
      " extracting: ./data/snli_1.0/Icon    \n",
      "  inflating: ./data/__MACOSX/snli_1.0/._Icon  \n",
      "  inflating: ./data/snli_1.0/README.txt  \n",
      "  inflating: ./data/__MACOSX/snli_1.0/._README.txt  \n",
      "  inflating: ./data/snli_1.0/snli_1.0_dev.jsonl  \n",
      "  inflating: ./data/snli_1.0/snli_1.0_dev.txt  \n",
      "  inflating: ./data/snli_1.0/snli_1.0_test.jsonl  \n",
      "  inflating: ./data/snli_1.0/snli_1.0_test.txt  \n",
      "  inflating: ./data/snli_1.0/snli_1.0_train.jsonl  \n",
      "  inflating: ./data/snli_1.0/snli_1.0_train.txt  \n",
      "  inflating: ./data/__MACOSX/._snli_1.0  \n"
     ]
    }
   ],
   "source": [
    "!curl -o ./data/SNLI1.0.zip https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
    "!unzip ./data/SNLI1.0.zip -d ./data/\n",
    "!rm -f ./data/SNLI1.0.zip ./data/_MACOSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(742)\n",
    "\n",
    "lines = []\n",
    "with open('./data/snli_1.0/snli_1.0_test.jsonl') as file:\n",
    "    for line in file:\n",
    "        lines.append(line)\n",
    "\n",
    "with open('./data/snli_mini.json', 'w') as outfile:\n",
    "    for i, line in enumerate(lines):\n",
    "        line = json.loads(line)\n",
    "        if i >= 100:\n",
    "            break\n",
    "        elif line['gold_label'] == '-':\n",
    "            continue\n",
    "        \n",
    "        newline = {\n",
    "            'premise': line['sentence1'],\n",
    "            'hypothesis': line['sentence2'],\n",
    "            'y': line['gold_label']\n",
    "        }\n",
    "        outfile.write(json.dumps(newline))\n",
    "        outfile.write('\\n')\n",
    "\n",
    "with open('./data/snli_large.json', 'w') as outfile:\n",
    "    for i, line in enumerate(lines):\n",
    "        line = json.loads(line)\n",
    "        if i >= 9000:\n",
    "            break\n",
    "        elif line['gold_label'] == '-':\n",
    "            continue\n",
    "        \n",
    "        newline = {\n",
    "            'premise': line['sentence1'],\n",
    "            'hypothesis': line['sentence2'],\n",
    "            'y': line['gold_label']\n",
    "        }\n",
    "        outfile.write(json.dumps(newline))\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD2.0 MRC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./data/SQuAD’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4268k  100 4268k    0     0  64.1M      0 --:--:-- --:--:-- --:--:-- 64.1M\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./data/SQuAD\n",
    "!curl -o ./data/SQuAD/dev-v2.0.json https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(742)\n",
    "\n",
    "data = []\n",
    "with open('./data/SQuAD/dev-v2.0.json') as file:\n",
    "    data = json.load(file)['data']\n",
    "\n",
    "samples = []\n",
    "\n",
    "for obj in data:\n",
    "    for para in obj['paragraphs']:\n",
    "        for qa in para['qas']:\n",
    "            sample = {\n",
    "                'title': obj['title'],\n",
    "                'context': para['context'],\n",
    "                'question': qa['question'],\n",
    "                'answers': qa['answers'],\n",
    "                'is_impossible': qa['is_impossible']\n",
    "            }\n",
    "            samples.append(sample)\n",
    "\n",
    "samples = random.sample(samples, 1250)\n",
    "\n",
    "with open('./data/squad2.0.json', 'w') as outfile:\n",
    "    for sample in samples:\n",
    "        outfile.write(json.dumps(sample))\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReClor MRC+ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1928k  100 1928k    0     0  27.2M      0 --:--:-- --:--:-- --:--:-- 27.2M\n",
      "Archive:  ./data/reclor_data.zip\n",
      "  inflating: ./data/reclor_data/question_type_names.json  \n",
      "  inflating: ./data/reclor_data/source_list.txt  \n",
      "  inflating: ./data/reclor_data/test.json  \n",
      "  inflating: ./data/reclor_data/train.json  \n",
      "  inflating: ./data/reclor_data/use_items.txt  \n",
      "  inflating: ./data/reclor_data/val.json  \n"
     ]
    }
   ],
   "source": [
    "!curl -L https://github.com/yuweihao/reclor/releases/download/v1/reclor_data.zip > ./data/reclor_data.zip\n",
    "!unzip -P for_non-commercial_research_purpose_only -d ./data/reclor_data ./data/reclor_data.zip\n",
    "!rm -f ./data/reclor_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(742)\n",
    "\n",
    "data = []\n",
    "with open('./data/reclor_data/train.json', 'r') as file:\n",
    "    data += json.load(file)\n",
    "with open('./data/reclor_data/val.json', 'r') as file:\n",
    "    data += json.load(file)\n",
    "\n",
    "with open('./data/reclor.json', 'w') as outfile:\n",
    "    samples = random.sample(data, 2500)\n",
    "\n",
    "    for sample in samples:\n",
    "        new_sample = {\n",
    "            'context': sample['context'],\n",
    "            'question': sample['question'],\n",
    "            'answer_choices': sample['answers'],\n",
    "            'answers': [sample['answers'][sample['label']]], # needed to not throw error with Engine.run()\n",
    "            'label': sample['label'],\n",
    "            'title': sample['id_string'],\n",
    "            'is_impossible': False\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(new_sample))\n",
    "        outfile.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8cdac629cdc94d4aa8662fbc21e9f38ae64bcca0f58ec2c045ef5888a763a92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
